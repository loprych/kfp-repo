{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "830a6047-e57d-4fd2-a68a-3cb1941dbc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kfp in /opt/conda/lib/python3.11/site-packages (2.9.0)\n",
      "Requirement already satisfied: kubernetes in /opt/conda/lib/python3.11/site-packages (30.1.0)\n",
      "Requirement already satisfied: minio in /opt/conda/lib/python3.11/site-packages (7.2.15)\n",
      "Requirement already satisfied: click<9,>=8.0.0 in /opt/conda/lib/python3.11/site-packages (from kfp) (8.1.7)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.7.3 in /opt/conda/lib/python3.11/site-packages (from kfp) (0.16)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/conda/lib/python3.11/site-packages (from kfp) (2.20.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.1 in /opt/conda/lib/python3.11/site-packages (from kfp) (2.35.0)\n",
      "Requirement already satisfied: google-cloud-storage<3,>=2.2.1 in /opt/conda/lib/python3.11/site-packages (from kfp) (2.18.2)\n",
      "Requirement already satisfied: kfp-pipeline-spec==0.4.0 in /opt/conda/lib/python3.11/site-packages (from kfp) (0.4.0)\n",
      "Requirement already satisfied: kfp-server-api<2.4.0,>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from kfp) (2.3.0)\n",
      "Requirement already satisfied: protobuf<5,>=4.21.1 in /opt/conda/lib/python3.11/site-packages (from kfp) (4.25.5)\n",
      "Requirement already satisfied: PyYAML<7,>=5.3 in /opt/conda/lib/python3.11/site-packages (from kfp) (6.0.2)\n",
      "Requirement already satisfied: requests-toolbelt<1,>=0.8.0 in /opt/conda/lib/python3.11/site-packages (from kfp) (0.10.1)\n",
      "Requirement already satisfied: tabulate<1,>=0.8.6 in /opt/conda/lib/python3.11/site-packages (from kfp) (0.9.0)\n",
      "Requirement already satisfied: urllib3<2.0.0 in /opt/conda/lib/python3.11/site-packages (from kfp) (1.26.20)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /opt/conda/lib/python3.11/site-packages (from kubernetes) (2024.8.30)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.11/site-packages (from kubernetes) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/lib/python3.11/site-packages (from kubernetes) (2.9.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.11/site-packages (from kubernetes) (1.8.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from kubernetes) (2.32.3)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.11/site-packages (from kubernetes) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /opt/conda/lib/python3.11/site-packages (from kubernetes) (3.2.2)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.11/site-packages (from minio) (23.1.0)\n",
      "Requirement already satisfied: pycryptodome in /opt/conda/lib/python3.11/site-packages (from minio) (3.21.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.11/site-packages (from minio) (4.12.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (1.65.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (1.24.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from google-auth<3,>=1.6.1->kfp) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.11/site-packages (from google-auth<3,>=1.6.1->kfp) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.11/site-packages (from google-auth<3,>=1.6.1->kfp) (4.9)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from google-cloud-storage<3,>=2.2.1->kfp) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.7.2 in /opt/conda/lib/python3.11/site-packages (from google-cloud-storage<3,>=2.2.1->kfp) (2.7.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.11/site-packages (from google-cloud-storage<3,>=2.2.1->kfp) (1.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->kubernetes) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->kubernetes) (3.10)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.11/site-packages (from argon2-cffi->minio) (21.2.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.1->kfp) (0.6.1)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from argon2-cffi-bindings->argon2-cffi->minio) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->minio) (2.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install kfp kubernetes minio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddbcec4-d349-4293-9a60-547b04c4ef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import os\n",
    "from minio import Minio\n",
    "from kfp import dsl\n",
    "from kfp.dsl import Input, Output, Artifact, Model, component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dca57cc-95aa-4e7f-b060-a1c1ce020a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image='lukoprych/yolov8-pipeline-base:latest',\n",
    "    packages_to_install=[]\n",
    ")\n",
    "def train(\n",
    "    trained_model_output: Output[Artifact],\n",
    "    training_logs_output: Output[Artifact],\n",
    "    minio_endpoint: str,\n",
    "    minio_access_key: str,\n",
    "    minio_secret_key: str,\n",
    "    minio_bucket: str,\n",
    "    dataset_path: str = \"dataset\",\n",
    "    base_model: str = \"yolov8n.pt\"\n",
    "):\n",
    "    import os\n",
    "    import subprocess\n",
    "    import tempfile\n",
    "    from pathlib import Path\n",
    "    import yaml\n",
    "    import shutil\n",
    "    from ultralytics import YOLO\n",
    "    from minio import Minio\n",
    "\n",
    "    client = Minio(\n",
    "        minio_endpoint,\n",
    "        access_key=minio_access_key,\n",
    "        secret_key=minio_secret_key,\n",
    "        secure=False\n",
    "    )\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        temp_dir = Path(temp_dir)\n",
    "        dataset_dir = temp_dir / \"dataset\"\n",
    "        model_dir = temp_dir / \"model\"\n",
    "        log_path = temp_dir / \"training_logs.txt\"\n",
    "        tensorboard_dir = temp_dir / \"tensorboard\"\n",
    "        tensorboard_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        for subdir in ['images/train', 'images/val', 'labels/train', 'labels/val']:\n",
    "            (dataset_dir / subdir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        objects = client.list_objects(minio_bucket, prefix=dataset_path, recursive=True)\n",
    "        for obj in objects:\n",
    "            if obj.object_name.endswith('/'):\n",
    "                continue\n",
    "            rel_path = obj.object_name[len(dataset_path):].lstrip('/')\n",
    "            if not rel_path:\n",
    "                continue\n",
    "            local_path = dataset_dir / rel_path\n",
    "            local_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            client.fget_object(minio_bucket, obj.object_name, str(local_path))\n",
    "\n",
    "        yaml_path = dataset_dir / \"data.yaml\"\n",
    "        if yaml_path.exists():\n",
    "            with open(yaml_path, 'r') as f:\n",
    "                data_config = yaml.safe_load(f)\n",
    "            data_config['train'] = str(dataset_dir/'images/train')\n",
    "            data_config['val'] = str(dataset_dir/'images/val')\n",
    "            with open(yaml_path, 'w') as f:\n",
    "                yaml.dump(data_config, f)\n",
    "\n",
    "        base_model_local = model_dir / base_model\n",
    "        client.fget_object(minio_bucket, f\"model/{base_model}\", str(base_model_local))\n",
    "\n",
    "        model = YOLO(str(base_model_local))\n",
    "        results = model.train(\n",
    "            data=str(yaml_path),\n",
    "            epochs=5,\n",
    "            imgsz=640,\n",
    "            batch=4,\n",
    "            patience=3,\n",
    "            device='cpu',\n",
    "            project=str(tensorboard_dir),  \n",
    "            name='',  \n",
    "            exist_ok=True,\n",
    "            plots=True,  \n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        trained_model_local = model_dir / \"trained_model.pt\"\n",
    "        model.save(str(trained_model_local))\n",
    "\n",
    "        client.fput_object(\n",
    "            minio_bucket,\n",
    "            \"model/trained_yolo_model.pt\",\n",
    "            str(trained_model_local)\n",
    "        )\n",
    "\n",
    "        with open(log_path, 'w') as f:\n",
    "            f.write(\"=== TRAINING COMPLETE ===\\n\")\n",
    "            f.write(str(results) + \"\\n\")\n",
    "\n",
    "        with open(trained_model_output.path, 'wb') as out_f:\n",
    "            out_f.write(open(trained_model_local, 'rb').read())\n",
    "\n",
    "        with open(training_logs_output.path, 'w') as log_art:\n",
    "            log_art.write(open(log_path, 'r').read())\n",
    "\n",
    "        # Upload TensorBoard files to MinIO\n",
    "        for file_path in tensorboard_dir.rglob('*'):\n",
    "            if file_path.is_file():\n",
    "                rel_path = file_path.relative_to(tensorboard_dir)\n",
    "                minio_key = f\"tensorboard/{rel_path}\"\n",
    "                print(f\"Uploading TensorBoard file: {minio_key}\")\n",
    "                client.fput_object(\n",
    "                    minio_bucket,\n",
    "                    minio_key,\n",
    "                    str(file_path)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f5d9b5a-cae0-48fa-a09d-a3aa5c740ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image='lukoprych/yolov8-pipeline-base:latest',\n",
    "    packages_to_install=['torch-model-archiver', 'torchserve']  \n",
    ")\n",
    "def package_to_mar(\n",
    "    trained_model_input: Input[Artifact],\n",
    "    trained_mar_output: Output[Artifact],\n",
    "    base_mar_output: Output[Artifact],\n",
    "    minio_endpoint: str,\n",
    "    minio_access_key: str,\n",
    "    minio_secret_key: str,\n",
    "    minio_bucket: str,\n",
    "    base_model_path: str = \"model/yolov8n.pt\"\n",
    "):\n",
    "    import tempfile\n",
    "    from pathlib import Path\n",
    "    from minio import Minio\n",
    "    import subprocess\n",
    "    import os\n",
    "\n",
    "    client = Minio(\n",
    "        minio_endpoint,\n",
    "        access_key=minio_access_key,\n",
    "        secret_key=minio_secret_key,\n",
    "        secure=False\n",
    "    )\n",
    "    \n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        temp_dir = Path(temp_dir)\n",
    "        trained_model_path = temp_dir / \"trained_yolo_model.pt\"\n",
    "        base_model_path_local = temp_dir / \"yolov8n.pt\"\n",
    "        model_store = temp_dir / \"model-store\"\n",
    "        model_store.mkdir(exist_ok=True)\n",
    "        handler_path = temp_dir / \"yolo_handler.py\"\n",
    "        \n",
    "        # Write handler\n",
    "        with open(handler_path, \"w\") as f:\n",
    "            f.write(\"\"\"import logging\n",
    "import os\n",
    "from collections import Counter\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from ultralytics import YOLO\n",
    "from ts.torch_handler.object_detector import ObjectDetector\n",
    "import io\n",
    "import base64\n",
    "from PIL import Image\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "try:\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    XLA_AVAILABLE = True\n",
    "except ImportError as error:\n",
    "    XLA_AVAILABLE = False\n",
    "\n",
    "class Yolov8Handler(ObjectDetector):\n",
    "    image_processing = transforms.Compose([\n",
    "        transforms.Resize(640),\n",
    "        transforms.CenterCrop(640),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Yolov8Handler, self).__init__()\n",
    "\n",
    "    def initialize(self, context):\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device(\"cuda\")\n",
    "        elif XLA_AVAILABLE:\n",
    "            self.device = xm.xla_device()\n",
    "        else:\n",
    "            self.device = torch.device(\"cpu\")\n",
    "\n",
    "        properties = context.system_properties\n",
    "        self.manifest = context.manifest\n",
    "        model_dir = properties.get(\"model_dir\")\n",
    "        self.model_pt_path = None\n",
    "        if \"serializedFile\" in self.manifest[\"model\"]:\n",
    "            serialized_file = self.manifest[\"model\"][\"serializedFile\"]\n",
    "            self.model_pt_path = os.path.join(model_dir, serialized_file)\n",
    "        self.model = self._load_torchscript_model(self.model_pt_path)\n",
    "        logger.debug(\"Model file %s loaded successfully\", self.model_pt_path)\n",
    "        self.initialized = True\n",
    "\n",
    "    def _load_torchscript_model(self, model_pt_path):\n",
    "        model = YOLO(model_pt_path)\n",
    "        model.to(self.device)\n",
    "        return model\n",
    "\n",
    "    def preprocess(self, requests):\n",
    "        images = []\n",
    "        for data in requests:\n",
    "            image = data.get(\"data\") or data.get(\"body\")\n",
    "            if isinstance(image, str):\n",
    "                image = base64.b64decode(image)\n",
    "            image = Image.open(io.BytesIO(image)).convert('RGB')\n",
    "            image = self.image_processing(image)\n",
    "            images.append(image)\n",
    "        return torch.stack(images).to(self.device)\n",
    "\n",
    "    def inference(self, data):\n",
    "        results = self.model(data)\n",
    "        return results\n",
    "\n",
    "    def postprocess(self, res):\n",
    "        output = []\n",
    "        for data in res:\n",
    "            classes = data.boxes.cls.tolist()\n",
    "            names = data.names\n",
    "            classes = map(lambda cls: names[int(cls)], classes)\n",
    "            result = Counter(classes)\n",
    "            output.append(dict(result))\n",
    "        return output\"\"\")\n",
    "\n",
    "        # Create requirements file\n",
    "        requirements_path = temp_dir / \"requirements.txt\"\n",
    "        with open(requirements_path, \"w\") as f:\n",
    "            f.write(\"torch\\nPillow\\nultralytics\\ntorchvision\\n\")\n",
    "\n",
    "        # Copy trained model\n",
    "        print(f\"Copying trained model to {trained_model_path}\")\n",
    "        with open(trained_model_input.path, 'rb') as in_f:\n",
    "            with open(trained_model_path, 'wb') as out_f:\n",
    "                out_f.write(in_f.read())\n",
    "        \n",
    "        if not trained_model_path.exists():\n",
    "            raise FileNotFoundError(f\"Trained model was not copied to {trained_model_path}\")\n",
    "        \n",
    "        # Get base model\n",
    "        print(f\"Getting base model from MinIO\")\n",
    "        client.fget_object(\n",
    "            minio_bucket,\n",
    "            base_model_path,\n",
    "            str(base_model_path_local)\n",
    "        )\n",
    "        \n",
    "        if not base_model_path_local.exists():\n",
    "            raise FileNotFoundError(f\"Base model was not downloaded to {base_model_path_local}\")\n",
    "        \n",
    "        # Package trained model\n",
    "        print(\"Creating trained model MAR file...\")\n",
    "        result = subprocess.run([\n",
    "            'torch-model-archiver',\n",
    "            '--model-name', 'trained_yolo_model', \n",
    "            '--version', '1.0',\n",
    "            '--serialized-file', str(trained_model_path),\n",
    "            '--handler', str(handler_path),\n",
    "            '--requirements-file', str(requirements_path),\n",
    "            '--export-path', str(model_store),\n",
    "            '--force'\n",
    "        ], capture_output=True, text=True)\n",
    "        \n",
    "        if result.returncode != 0:\n",
    "            raise Exception(f\"Error creating trained MAR file: {result.stderr}\")\n",
    "        \n",
    "        # Package base model\n",
    "        print(\"Creating base model MAR file...\")\n",
    "        result = subprocess.run([\n",
    "            'torch-model-archiver',\n",
    "            '--model-name', 'base_yolo_model', \n",
    "            '--version', '1.0',\n",
    "            '--serialized-file', str(base_model_path_local),\n",
    "            '--handler', str(handler_path),\n",
    "            '--requirements-file', str(requirements_path),\n",
    "            '--export-path', str(model_store),\n",
    "            '--force'\n",
    "        ], capture_output=True, text=True)\n",
    "        \n",
    "        if result.returncode != 0:\n",
    "            raise Exception(f\"Error creating base MAR file: {result.stderr}\")\n",
    "            \n",
    "        trained_mar_path = model_store / \"trained_yolo_model.mar\"\n",
    "        base_mar_path = model_store / \"base_yolo_model.mar\"\n",
    "        \n",
    "        if not trained_mar_path.exists() or not base_mar_path.exists():\n",
    "            raise FileNotFoundError(f\"MAR files were not created: {trained_mar_path}, {base_mar_path}\")\n",
    "            \n",
    "        print(f\"MAR files created at: {trained_mar_path} and {base_mar_path}\")\n",
    "        \n",
    "        # Save to MinIO\n",
    "        print(\"Saving to MinIO...\")\n",
    "        client.fput_object(\n",
    "            minio_bucket,\n",
    "            \"kserve/model-store/trained_yolo_model.mar\",\n",
    "            str(trained_mar_path)\n",
    "        )\n",
    "        client.fput_object(\n",
    "            minio_bucket,\n",
    "            \"kserve/model-store/base_yolo_model.mar\",\n",
    "            str(base_mar_path)\n",
    "        )\n",
    "        \n",
    "        # Save outputs\n",
    "        print(\"Saving outputs...\")\n",
    "        with open(trained_mar_output.path, 'wb') as out_f:\n",
    "            out_f.write(open(trained_mar_path, 'rb').read())\n",
    "        with open(base_mar_output.path, 'wb') as out_f:\n",
    "            out_f.write(open(base_mar_path, 'rb').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60e6cb1b-5e41-452b-b571-19f4b38bbf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image='lukoprych/yolov8-pipeline-base:latest',\n",
    "    packages_to_install=[] \n",
    ")\n",
    "def evaluate_model(\n",
    "    trained_model_input: Input[Artifact],\n",
    "    evaluation_logs_output: Output[Artifact],\n",
    "    minio_endpoint: str,\n",
    "    minio_access_key: str,\n",
    "    minio_secret_key: str,\n",
    "    minio_bucket: str\n",
    "):\n",
    "    import tempfile\n",
    "    from pathlib import Path\n",
    "    from ultralytics import YOLO\n",
    "    from minio import Minio\n",
    "    from datetime import datetime\n",
    "    import os\n",
    "    \n",
    "    client = Minio(\n",
    "        minio_endpoint,\n",
    "        access_key=minio_access_key,\n",
    "        secret_key=minio_secret_key,\n",
    "        secure=False\n",
    "    )\n",
    "    \n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        temp_dir = Path(temp_dir)\n",
    "        model_local_path = temp_dir / \"trained_model.pt\"\n",
    "        eval_log_path = temp_dir / \"eval_logs.txt\"\n",
    "        \n",
    "        with open(trained_model_input.path, 'rb') as in_f:\n",
    "            with open(model_local_path, 'wb') as out_f:\n",
    "                out_f.write(in_f.read())\n",
    "        \n",
    "        image_paths = []\n",
    "        for img_name in [\"zidane.jpg\", \"bus.jpg\"]:\n",
    "            image_local = temp_dir / img_name\n",
    "            try:\n",
    "                client.fget_object(\n",
    "                    minio_bucket,\n",
    "                    f\"images/{img_name}\",\n",
    "                    str(image_local)\n",
    "                )\n",
    "                image_paths.append(image_local)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not download {img_name}: {e}\")\n",
    "                # Try to download from ultralytics\n",
    "                try:\n",
    "                    from ultralytics.utils.downloads import download\n",
    "                    download(f\"https://ultralytics.com/images/{img_name}\", str(image_local))\n",
    "                    image_paths.append(image_local)\n",
    "                except Exception as e2:\n",
    "                    print(f\"Could not download image from backup source: {e2}\")\n",
    "        \n",
    "        model = YOLO(str(model_local_path))\n",
    "        \n",
    "        with open(eval_log_path, 'w') as f:\n",
    "            f.write(\"=== EVALUATION RESULTS ===\\n\")\n",
    "            for img_path in image_paths:\n",
    "                f.write(f\"\\nEvaluating image: {img_path.name}\\n\")\n",
    "                results = model(str(img_path))\n",
    "                f.write(f\"Detection results: {results[0].boxes.shape[0]} objects found\\n\")\n",
    "                \n",
    "                # Detailed metrics\n",
    "                boxes = results[0].boxes\n",
    "                if len(boxes) > 0:\n",
    "                    f.write(f\"Average confidence: {boxes.conf.mean().item():.4f}\\n\")\n",
    "                    f.write(f\"Maximum confidence: {boxes.conf.max().item():.4f}\\n\")\n",
    "                    \n",
    "                    # Class distribution\n",
    "                    classes = boxes.cls.tolist()\n",
    "                    names = results[0].names\n",
    "                    class_counts = {}\n",
    "                    for cls in classes:\n",
    "                        cls_name = names[int(cls)]\n",
    "                        class_counts[cls_name] = class_counts.get(cls_name, 0) + 1\n",
    "                    \n",
    "                    f.write(\"Class distribution:\\n\")\n",
    "                    for cls_name, count in class_counts.items():\n",
    "                        f.write(f\"  - {cls_name}: {count}\\n\")\n",
    "                        \n",
    "                f.write(f\"Results: {results}\\n\")\n",
    "                f.write(\"-\" * 40 + \"\\n\")\n",
    "        \n",
    "        # Save logs to output artifact\n",
    "        with open(evaluation_logs_output.path, 'w') as log_art:\n",
    "            log_art.write(open(eval_log_path, 'r').read())\n",
    "\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        log_filename = f\"logs/eval_logs_{timestamp}.txt\"\n",
    "\n",
    "        # Also save to MinIO with specific name\n",
    "        client.put_object(\n",
    "            minio_bucket,\n",
    "            log_filename,\n",
    "            open(eval_log_path, 'rb'),\n",
    "            length=os.path.getsize(str(eval_log_path))\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "849ca085-b254-4575-a651-ecc5f260dc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image='lukoprych/yolov8-pipeline-base:latest',\n",
    "    packages_to_install=[]\n",
    ")\n",
    "def inference_model(\n",
    "    trained_model_input: Input[Artifact],\n",
    "    inference_logs_output: Output[Artifact],\n",
    "    minio_endpoint: str,\n",
    "    minio_access_key: str,\n",
    "    minio_secret_key: str,\n",
    "    minio_bucket: str\n",
    "):\n",
    "    import os\n",
    "    import tempfile\n",
    "    import time\n",
    "    from pathlib import Path\n",
    "    from ultralytics import YOLO\n",
    "    from minio import Minio\n",
    "    from datetime import datetime\n",
    "    \n",
    "    client = Minio(\n",
    "        minio_endpoint,\n",
    "        access_key=minio_access_key,\n",
    "        secret_key=minio_secret_key,\n",
    "        secure=False\n",
    "    )\n",
    "    \n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        temp_dir = Path(temp_dir)\n",
    "        model_local_path = temp_dir / \"trained_model.pt\"\n",
    "        inference_log_path = temp_dir / \"inference_logs.txt\"\n",
    "        result_images_dir = temp_dir / \"results\"\n",
    "        result_images_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        with open(trained_model_input.path, 'rb') as in_f:\n",
    "            with open(model_local_path, 'wb') as out_f:\n",
    "                out_f.write(in_f.read())\n",
    "        \n",
    "        # Get test images\n",
    "        images = [\"zidane.jpg\", \"bus.jpg\"]\n",
    "        local_img_paths = []\n",
    "        \n",
    "        for img in images:\n",
    "            local_img = temp_dir / img\n",
    "            try:\n",
    "                client.fget_object(\n",
    "                    minio_bucket,\n",
    "                    f\"images/{img}\",\n",
    "                    str(local_img)\n",
    "                )\n",
    "                local_img_paths.append(local_img)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not download {img}: {e}\")\n",
    "                # Try to download from ultralytics\n",
    "                try:\n",
    "                    from ultralytics.utils.downloads import download\n",
    "                    download(f\"https://ultralytics.com/images/{img}\", str(local_img))\n",
    "                    local_img_paths.append(local_img)\n",
    "                except Exception as e2:\n",
    "                    print(f\"Could not download image from backup source: {e2}\")\n",
    "        \n",
    "        model = YOLO(str(model_local_path))\n",
    "        timestamp = int(time.time())\n",
    "        \n",
    "        with open(inference_log_path, 'w') as f:\n",
    "            f.write(\"=== INFERENCE RESULTS ===\\n\")\n",
    "            f.write(f\"Timestamp: {timestamp}\\n\")\n",
    "            f.write(f\"Model: {model_local_path}\\n\\n\")\n",
    "            \n",
    "            for img_path in local_img_paths:\n",
    "                f.write(f\"Image: {img_path.name}\\n\")\n",
    "                # Run inference with visualization\n",
    "                results = model(str(img_path), save=True, save_dir=str(result_images_dir))\n",
    "                \n",
    "                # Save detailed results\n",
    "                boxes = results[0].boxes\n",
    "                f.write(f\"Detection count: {len(boxes)}\\n\")\n",
    "                \n",
    "                if len(boxes) > 0:\n",
    "                    f.write(f\"Average confidence: {boxes.conf.mean().item():.4f}\\n\")\n",
    "                    f.write(f\"Classes detected: {len(set(boxes.cls.tolist()))}\\n\")\n",
    "                    \n",
    "                    # Class distribution with confidence\n",
    "                    classes = boxes.cls.tolist()\n",
    "                    confs = boxes.conf.tolist()\n",
    "                    names = results[0].names\n",
    "                    \n",
    "                    f.write(\"Detections:\\n\")\n",
    "                    for i, (cls, conf) in enumerate(zip(classes, confs)):\n",
    "                        cls_name = names[int(cls)]\n",
    "                        f.write(f\"  {i+1}. {cls_name} (confidence: {conf:.4f})\\n\")\n",
    "                \n",
    "                f.write(f\"Raw results: {results}\\n\")\n",
    "                f.write(\"-\" * 60 + \"\\n\\n\")\n",
    "                \n",
    "                # Upload result images to MinIO if they exist\n",
    "                result_img = result_images_dir / img_path.name\n",
    "                if result_img.exists():\n",
    "                    try:\n",
    "                        client.fput_object(\n",
    "                            minio_bucket,\n",
    "                            f\"inference/results/{timestamp}_{img_path.name}\",\n",
    "                            str(result_img)\n",
    "                        )\n",
    "                    except Exception as e:\n",
    "                        f.write(f\"Failed to upload result image: {e}\\n\")\n",
    "        \n",
    "        # Save to artifact output\n",
    "        with open(inference_logs_output.path, 'w') as log_art:\n",
    "            log_art.write(open(inference_log_path, 'r').read())\n",
    "\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        log_filename = f\"logs/inference_logs_{timestamp}.txt\"\n",
    "        \n",
    "        # Also save to MinIO with specific name\n",
    "        client.put_object(\n",
    "            minio_bucket,\n",
    "            log_filename,\n",
    "            open(inference_log_path, 'rb'),\n",
    "            length=os.path.getsize(str(inference_log_path))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0156ce51-ceaf-4e70-91ad-a2c398ea84aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image='lukoprych/yolov8-pipeline-base:latest',\n",
    "    packages_to_install=[]\n",
    ")\n",
    "def compare_models(\n",
    "    trained_model_input: Input[Artifact],\n",
    "    model_comparison_output: Output[Artifact],\n",
    "    minio_endpoint: str,\n",
    "    minio_access_key: str,\n",
    "    minio_secret_key: str,\n",
    "    minio_bucket: str,\n",
    "    base_model_path: str = \"model/yolov8n.pt\",\n",
    "    previous_trained_model_path: str = \"model/trained_yolo_model.pt\",\n",
    "    accuracy_threshold: float = 0.03  # 3% improvement required\n",
    "):\n",
    "    \n",
    "    import os\n",
    "    import tempfile\n",
    "    import json\n",
    "    from pathlib import Path\n",
    "    from ultralytics import YOLO\n",
    "    from minio import Minio\n",
    "    import time\n",
    "    \n",
    "    client = Minio(\n",
    "        minio_endpoint,\n",
    "        access_key=minio_access_key,\n",
    "        secret_key=minio_secret_key,\n",
    "        secure=False\n",
    "    )\n",
    "    \n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        temp_dir = Path(temp_dir)\n",
    "        new_model_path = temp_dir / \"new_model.pt\"\n",
    "        prev_model_path = temp_dir / \"previous_model.pt\"\n",
    "        base_model_local_path = temp_dir / \"base_model.pt\"\n",
    "        validation_images_dir = temp_dir / \"validation_images\"\n",
    "        validation_images_dir.mkdir(exist_ok=True)\n",
    "        comparison_results_path = temp_dir / \"comparison_results.json\"\n",
    "        \n",
    "        # Copy the new model from input\n",
    "        with open(trained_model_input.path, 'rb') as in_f:\n",
    "            with open(new_model_path, 'wb') as out_f:\n",
    "                out_f.write(in_f.read())\n",
    "        \n",
    "        # Check if this is the first training run or if previous trained model exists\n",
    "        previous_model_exists = True\n",
    "        try:\n",
    "            # Use timestamp to check if the previous trained model is not the same as current one\n",
    "            prev_stats = client.stat_object(minio_bucket, previous_trained_model_path)\n",
    "            curr_time = time.time()\n",
    "            # If the model was created in the last hour, it's likely from the current run\n",
    "            # In that case, compare against the base model\n",
    "            if (curr_time - prev_stats.last_modified.timestamp()) < 3600:\n",
    "                print(\"Previous trained model is likely from current run, comparing against base model\")\n",
    "                client.fget_object(\n",
    "                    minio_bucket,\n",
    "                    base_model_path,\n",
    "                    str(prev_model_path)\n",
    "                )\n",
    "            else:\n",
    "                client.fget_object(\n",
    "                    minio_bucket,\n",
    "                    previous_trained_model_path,\n",
    "                    str(prev_model_path)\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(f\"Previous trained model not found: {e}\")\n",
    "            print(\"Will compare against base model instead\")\n",
    "            try:\n",
    "                client.fget_object(\n",
    "                    minio_bucket,\n",
    "                    base_model_path,\n",
    "                    str(prev_model_path)\n",
    "                )\n",
    "            except Exception as e2:\n",
    "                print(f\"Base model not found either: {e2}\")\n",
    "                previous_model_exists = False\n",
    "        \n",
    "        # Get validation images\n",
    "        val_images = [\"zidane.jpg\", \"bus.jpg\"]\n",
    "        for img in val_images:\n",
    "            local_img = validation_images_dir / img\n",
    "            try:\n",
    "                client.fget_object(\n",
    "                    minio_bucket,\n",
    "                    f\"images/{img}\",\n",
    "                    str(local_img)\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not fetch validation image {img}: {e}\")\n",
    "                # Try to use demo images from ultralytics\n",
    "                import shutil\n",
    "                from ultralytics.utils.downloads import download\n",
    "                download(f\"https://ultralytics.com/images/{img}\", str(local_img))\n",
    "        \n",
    "        # Load new model\n",
    "        new_model = YOLO(str(new_model_path))\n",
    "        \n",
    "        # Evaluate new model\n",
    "        new_model_metrics = {}\n",
    "        for img_name in val_images:\n",
    "            img_path = validation_images_dir / img_name\n",
    "            if not img_path.exists():\n",
    "                print(f\"Skipping missing image: {img_name}\")\n",
    "                continue\n",
    "                \n",
    "            results = new_model(str(img_path))\n",
    "            # Extract confidence scores and metrics\n",
    "            boxes = results[0].boxes\n",
    "            new_model_metrics[img_name] = {\n",
    "                'num_detections': len(boxes),\n",
    "                'avg_confidence': float(boxes.conf.mean()) if len(boxes) > 0 else 0,\n",
    "                'max_confidence': float(boxes.conf.max()) if len(boxes) > 0 else 0\n",
    "            }\n",
    "        \n",
    "        comparison_result = {\n",
    "            'new_model_metrics': new_model_metrics,\n",
    "            'previous_model_metrics': {},\n",
    "            'is_better': True,  \n",
    "            'improvement': 0,\n",
    "            'message': 'First model, no comparison available'\n",
    "        }\n",
    "        \n",
    "        if previous_model_exists:\n",
    "            # Load previous model\n",
    "            prev_model = YOLO(str(prev_model_path))\n",
    "            \n",
    "            # Evaluate previous model\n",
    "            prev_model_metrics = {}\n",
    "            for img_name in val_images:\n",
    "                img_path = validation_images_dir / img_name\n",
    "                if not img_path.exists():\n",
    "                    continue\n",
    "                    \n",
    "                results = prev_model(str(img_path))\n",
    "                boxes = results[0].boxes\n",
    "                prev_model_metrics[img_name] = {\n",
    "                    'num_detections': len(boxes),\n",
    "                    'avg_confidence': float(boxes.conf.mean()) if len(boxes) > 0 else 0,\n",
    "                    'max_confidence': float(boxes.conf.max()) if len(boxes) > 0 else 0\n",
    "                }\n",
    "            \n",
    "            comparison_result['previous_model_metrics'] = prev_model_metrics\n",
    "            \n",
    "            # Calculate metrics:\n",
    "            # 1. Average confidence across all images\n",
    "            # 2. Total detections (weighted by confidence)\n",
    "            \n",
    "            # Get valid images that both models processed\n",
    "            valid_images = set(new_model_metrics.keys()) & set(prev_model_metrics.keys())\n",
    "            if not valid_images:\n",
    "                comparison_result['message'] = \"No common images to compare models\"\n",
    "                comparison_result['is_better'] = True\n",
    "            else:\n",
    "                # Calculate weighted detection score (num_detections * avg_confidence)\n",
    "                new_score = sum(\n",
    "                    new_model_metrics[img]['num_detections'] * new_model_metrics[img]['avg_confidence']\n",
    "                    for img in valid_images\n",
    "                ) / len(valid_images)\n",
    "                \n",
    "                prev_score = sum(\n",
    "                    prev_model_metrics[img]['num_detections'] * prev_model_metrics[img]['avg_confidence']\n",
    "                    for img in valid_images\n",
    "                ) / len(valid_images)\n",
    "                \n",
    "                improvement = (new_score - prev_score) / max(prev_score, 0.001)\n",
    "                \n",
    "                comparison_result['improvement'] = float(improvement)\n",
    "                comparison_result['is_better'] = improvement >= accuracy_threshold\n",
    "                \n",
    "                if comparison_result['is_better']:\n",
    "                    comparison_result['message'] = f\"New model is better by {improvement:.2%}\"\n",
    "                else:\n",
    "                    comparison_result['message'] = (\n",
    "                        f\"New model does not meet improvement threshold. \"\n",
    "                        f\"Improvement: {improvement:.2%}, Required: {accuracy_threshold:.2%}\"\n",
    "                    )\n",
    "        \n",
    "        # Save comparison results\n",
    "        with open(comparison_results_path, 'w') as f:\n",
    "            json.dump(comparison_result, f, indent=2)\n",
    "        \n",
    "        # Save to MinIO as well\n",
    "        client.put_object(\n",
    "            minio_bucket,\n",
    "            \"comparison/model_comparison.json\",\n",
    "            open(comparison_results_path, 'rb'),\n",
    "            length=os.path.getsize(str(comparison_results_path))\n",
    "        )\n",
    "        \n",
    "        with open(model_comparison_output.path, 'w') as out_f:\n",
    "            out_f.write(open(comparison_results_path, 'r').read())\n",
    "\n",
    "        print(f\"Comparison complete: {comparison_result['message']}\")\n",
    "        print(f\"Model is better: {comparison_result['is_better']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8efdfe2-86f4-48a9-8829-9d5a8a775d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image='python:3.9',\n",
    "    packages_to_install=['kubernetes', 'PyYAML', 'minio']\n",
    ")\n",
    "def serve(\n",
    "    trained_mar_input: Input[Artifact],\n",
    "    base_mar_input: Input[Artifact],\n",
    "    model_comparison_input: Input[Artifact],\n",
    "    minio_endpoint: str,\n",
    "    minio_access_key: str,\n",
    "    minio_secret_key: str,\n",
    "    minio_bucket: str,\n",
    "    service_namespace: str = \"kubeflow-user-example-com\"\n",
    "):\n",
    "    import kubernetes\n",
    "    import yaml\n",
    "    import os\n",
    "    import json\n",
    "    from minio import Minio\n",
    "    import tempfile\n",
    "    from pathlib import Path\n",
    "    import io\n",
    "    \n",
    "    # Connect to MinIO\n",
    "    client = Minio(\n",
    "        minio_endpoint,\n",
    "        access_key=minio_access_key,\n",
    "        secret_key=minio_secret_key,\n",
    "        secure=False\n",
    "    )\n",
    "    \n",
    "    # Read comparison results to determine which model to serve\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        temp_dir = Path(temp_dir)\n",
    "        comparison_path = temp_dir / \"comparison_results.json\"\n",
    "        deploy_log_path = temp_dir / \"deployment_logs.txt\"\n",
    "        model_path = temp_dir / \"model.mar\"\n",
    "        \n",
    "        with open(model_comparison_input.path, 'r') as in_f:\n",
    "            with open(comparison_path, 'w') as out_f:\n",
    "                out_f.write(in_f.read())\n",
    "                \n",
    "        with open(comparison_path, 'r') as f:\n",
    "            comparison_results = json.load(f)\n",
    "        \n",
    "        with open(deploy_log_path, 'w') as log_f:\n",
    "            log_f.write(\"=== DEPLOYMENT LOGS ===\\n\")\n",
    "            \n",
    "            if comparison_results.get('is_better', True):\n",
    "                log_f.write(\"Selecting trained model - it performs better\\n\")\n",
    "                log_f.write(f\"Improvement: {comparison_results.get('improvement', 0):.2%}\\n\")\n",
    "                # Copy trained model to local path\n",
    "                with open(trained_mar_input.path, 'rb') as src, open(model_path, 'wb') as dst:\n",
    "                    dst.write(src.read())\n",
    "            else:\n",
    "                log_f.write(\"Selecting base model - trained model did not show sufficient improvement\\n\")\n",
    "                # Copy base model to local path\n",
    "                with open(base_mar_input.path, 'rb') as src, open(model_path, 'wb') as dst:\n",
    "                    dst.write(src.read())\n",
    "            \n",
    "            log_f.write(f\"Reason: {comparison_results.get('message', 'No comparison data available')}\\n\")\n",
    "            \n",
    "            # Upload selected model to MinIO using the file path\n",
    "            try:\n",
    "                client.fput_object(\n",
    "                    minio_bucket,\n",
    "                    \"kserve/model-store/yolo_model.mar\",\n",
    "                    str(model_path)\n",
    "                )\n",
    "                log_f.write(\"Successfully uploaded model to MinIO\\n\")\n",
    "            except Exception as e:\n",
    "                log_f.write(f\"Error uploading model to MinIO: {str(e)}\\n\")\n",
    "                raise\n",
    "        \n",
    "        # Upload deployment logs to MinIO\n",
    "        try:\n",
    "            client.fput_object(\n",
    "                minio_bucket,\n",
    "                \"deployment/deployment_logs.txt\",\n",
    "                str(deploy_log_path)\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error uploading deployment logs: {str(e)}\")\n",
    "    \n",
    "    # Configure Kubernetes\n",
    "    kubernetes.config.load_incluster_config()\n",
    "    api_instance = kubernetes.client.CustomObjectsApi()\n",
    "    \n",
    "    # Use fixed service definition with correct storageUri path\n",
    "    inference_service = {\n",
    "        \"apiVersion\": \"serving.kserve.io/v1beta1\",\n",
    "        \"kind\": \"InferenceService\",\n",
    "        \"metadata\": {\n",
    "            \"name\": \"yolov8\",\n",
    "            \"namespace\": service_namespace\n",
    "        },\n",
    "        \"spec\": {\n",
    "            \"predictor\": {\n",
    "                \"serviceAccountName\": \"sa-minio-kserve\",\n",
    "                \"model\": {\n",
    "                    \"modelFormat\": {\n",
    "                        \"name\": \"pytorch\"\n",
    "                    },\n",
    "                    \"storageUri\": \"s3://mlpipeline/kserve\",\n",
    "                    \"protocolVersion\": \"v2\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f\"Deploying InferenceService 'yolov8' in namespace {service_namespace}\")\n",
    "    print(f\"Using storageUri: s3://mlpipeline/kserve\")\n",
    "    \n",
    "    try:\n",
    "        response = api_instance.create_namespaced_custom_object(\n",
    "            group=\"serving.kserve.io\",\n",
    "            version=\"v1beta1\",\n",
    "            namespace=service_namespace,\n",
    "            plural=\"inferenceservices\",\n",
    "            body=inference_service\n",
    "        )\n",
    "        print(f\"InferenceService created: {response['metadata']['name']}\")\n",
    "    except kubernetes.client.rest.ApiException as e:\n",
    "        if e.status == 409:\n",
    "            print(\"InferenceService already exists, updating\")\n",
    "            response = api_instance.replace_namespaced_custom_object(\n",
    "                group=\"serving.kserve.io\",\n",
    "                version=\"v1beta1\",\n",
    "                namespace=service_namespace,\n",
    "                plural=\"inferenceservices\",\n",
    "                name=\"yolov8\",\n",
    "                body=inference_service\n",
    "            )\n",
    "            print(f\"InferenceService updated: {response['metadata']['name']}\")\n",
    "        else:\n",
    "            print(f\"Error creating/updating InferenceService: {e}\")\n",
    "            raise\n",
    "    \n",
    "    print(\"InferenceService has been deployed. Check its status manually.\")\n",
    "    print(f\"Service will be available at: yolov8.{service_namespace}.example.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c26ba1c-0d20-44c8-b207-9ba1fd8a4777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compilation successful -> yolo_pipeline.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/kfp/client/client.py:159: FutureWarning: This client only works with Kubeflow Pipeline v2.0.0-beta.2 and later versions.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/8c2d2d34-3cb0-45f5-b63b-1e7a210c93c5\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/5b9728c1-fbc9-43bf-a138-d69433fdbab9\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline run submitted: 5b9728c1-fbc9-43bf-a138-d69433fdbab9\n"
     ]
    }
   ],
   "source": [
    "@dsl.pipeline(\n",
    "    name='YOLOv8 Pipeline',\n",
    "    description='YOLOv8 pipeline'\n",
    ")\n",
    "def yolo_pipeline():\n",
    "    config = {\n",
    "        'minio_endpoint': 'minio-service.kubeflow:9000',\n",
    "        'minio_access_key': 'minio',\n",
    "        'minio_secret_key': 'minio123',\n",
    "        'minio_bucket': 'mlpipeline'\n",
    "    }\n",
    "    \n",
    "    # Training step with TensorBoard\n",
    "    train_task = train(\n",
    "        **config,\n",
    "        base_model=\"yolov8n.pt\",\n",
    "        #dataset_path=\"dataset\"\n",
    "    ).set_display_name(\"train\")\n",
    "    \n",
    "    train_task.set_cpu_request('2')\n",
    "    train_task.set_memory_request('4G')\n",
    "    \n",
    "    # Package both models to MAR\n",
    "    package_task = package_to_mar(\n",
    "        trained_model_input=train_task.outputs[\"trained_model_output\"],\n",
    "        base_model_path=\"model/yolov8n.pt\",\n",
    "        **config\n",
    "    )\n",
    "    package_task.after(train_task)\n",
    "    \n",
    "    # Evaluation step\n",
    "    eval_task = evaluate_model(\n",
    "        trained_model_input=train_task.outputs[\"trained_model_output\"],\n",
    "        **config\n",
    "    )\n",
    "    eval_task.after(package_task)\n",
    "    \n",
    "    # Inference step\n",
    "    inference_task = inference_model(\n",
    "        trained_model_input=train_task.outputs[\"trained_model_output\"],\n",
    "        **config\n",
    "    )\n",
    "    inference_task.after(eval_task)\n",
    "    \n",
    "    # Model comparison quality gate\n",
    "    compare_task = compare_models(\n",
    "        trained_model_input=train_task.outputs[\"trained_model_output\"],\n",
    "        **config,\n",
    "        base_model_path=\"model/yolov8n.pt\",\n",
    "        previous_trained_model_path=\"model/trained_yolo_model.pt\",\n",
    "        accuracy_threshold=0.03  # Require 3% improvement\n",
    "    )\n",
    "    compare_task.after(inference_task)\n",
    "    \n",
    "    # Conditionally serve the better model\n",
    "    serve_task = serve(\n",
    "        trained_mar_input=package_task.outputs[\"trained_mar_output\"],\n",
    "        base_mar_input=package_task.outputs[\"base_mar_output\"],\n",
    "        model_comparison_input=compare_task.outputs[\"model_comparison_output\"],\n",
    "        **config,\n",
    "        service_namespace=\"kubeflow-user-example-com\"\n",
    "    )\n",
    "    serve_task.after(compare_task)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from kfp import compiler\n",
    "    pipeline_package_path = \"yolo_pipeline.yaml\"\n",
    "    compiler.Compiler().compile(\n",
    "        pipeline_func=yolo_pipeline,\n",
    "        package_path=pipeline_package_path\n",
    "    )\n",
    "    print(f\"Compilation successful -> {pipeline_package_path}\")\n",
    "    \n",
    "    from kfp import Client\n",
    "    client = Client()\n",
    "    run = client.create_run_from_pipeline_package(\n",
    "        pipeline_file=pipeline_package_path,\n",
    "        arguments={}\n",
    "    )\n",
    "    print(\"Pipeline run submitted:\", run.run_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
